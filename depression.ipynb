{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "692d1c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "      <th>degree_level</th>\n",
       "      <th>degree_cluster</th>\n",
       "      <th>degree_emb_pca_1</th>\n",
       "      <th>degree_emb_pca_2</th>\n",
       "      <th>degree_emb_pca_3</th>\n",
       "      <th>degree_emb_pca_4</th>\n",
       "      <th>degree_emb_pca_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.253879</td>\n",
       "      <td>0.243325</td>\n",
       "      <td>0.343663</td>\n",
       "      <td>-0.337468</td>\n",
       "      <td>-0.045405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221702</td>\n",
       "      <td>0.239069</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.184283</td>\n",
       "      <td>0.126231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061047</td>\n",
       "      <td>-0.276469</td>\n",
       "      <td>0.533775</td>\n",
       "      <td>-0.294401</td>\n",
       "      <td>0.217425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235426</td>\n",
       "      <td>0.208007</td>\n",
       "      <td>0.092394</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.243518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692180</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.020745</td>\n",
       "      <td>-0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.268271</td>\n",
       "      <td>0.238251</td>\n",
       "      <td>-0.039036</td>\n",
       "      <td>0.147155</td>\n",
       "      <td>0.202336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692180</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.020745</td>\n",
       "      <td>-0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.032905</td>\n",
       "      <td>-0.350849</td>\n",
       "      <td>0.032525</td>\n",
       "      <td>0.216158</td>\n",
       "      <td>0.021605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692180</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.020745</td>\n",
       "      <td>-0.018673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692180</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.020745</td>\n",
       "      <td>-0.018673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Academic Pressure  Work Pressure  CGPA  Study Satisfaction  \\\n",
       "0       0   33                5.0            0.0  8.97                   2   \n",
       "1       0   31                3.0            0.0  7.03                   5   \n",
       "2       0   29                2.0            0.0  5.70                   3   \n",
       "3       0   30                3.0            0.0  9.54                   4   \n",
       "4       1   30                2.0            0.0  8.04                   4   \n",
       "5       0   33                3.0            0.0  7.03                   4   \n",
       "6       1   19                2.0            0.0  8.52                   4   \n",
       "7       0   25                5.0            0.0  6.51                   2   \n",
       "8       1   20                5.0            0.0  7.25                   3   \n",
       "9       0   19                2.0            0.0  7.83                   2   \n",
       "\n",
       "   Sleep Duration  Dietary Habits  Have you ever had suicidal thoughts ?  \\\n",
       "0               1             1.0                                      1   \n",
       "1               0             1.0                                      0   \n",
       "2               0             1.0                                      0   \n",
       "3               1             1.0                                      0   \n",
       "4               0             0.0                                      0   \n",
       "5               0             1.0                                      1   \n",
       "6               0             0.0                                      0   \n",
       "7               0             0.0                                      1   \n",
       "8               1             1.0                                      1   \n",
       "9               1             0.0                                      0   \n",
       "\n",
       "   Work/Study Hours  Financial Stress  Family History of Mental Illness  \\\n",
       "0                 3                 1                                 0   \n",
       "1                 9                 1                                 1   \n",
       "2                 4                 1                                 0   \n",
       "3                 1                 2                                 0   \n",
       "4                 0                 1                                 1   \n",
       "5                10                 2                                 1   \n",
       "6                 6                 2                                 1   \n",
       "7                 2                 5                                 1   \n",
       "8                10                 3                                 0   \n",
       "9                 6                 3                                 0   \n",
       "\n",
       "   Depression  degree_level  degree_cluster  degree_emb_pca_1  \\\n",
       "0           1             1               4          0.253879   \n",
       "1           0             1               1          0.221702   \n",
       "2           0             3               2          0.061047   \n",
       "3           0             1               4          0.235426   \n",
       "4           0             0               0         -0.692180   \n",
       "5           0             1               4          0.268271   \n",
       "6           0             0               0         -0.692180   \n",
       "7           1             2               2         -0.032905   \n",
       "8           1             0               0         -0.692180   \n",
       "9           0             0               0         -0.692180   \n",
       "\n",
       "   degree_emb_pca_2  degree_emb_pca_3  degree_emb_pca_4  degree_emb_pca_5  \n",
       "0          0.243325          0.343663         -0.337468         -0.045405  \n",
       "1          0.239069          0.015781          0.184283          0.126231  \n",
       "2         -0.276469          0.533775         -0.294401          0.217425  \n",
       "3          0.208007          0.092394          0.084074          0.243518  \n",
       "4          0.082920         -0.029387         -0.020745         -0.018673  \n",
       "5          0.238251         -0.039036          0.147155          0.202336  \n",
       "6          0.082920         -0.029387         -0.020745         -0.018673  \n",
       "7         -0.350849          0.032525          0.216158          0.021605  \n",
       "8          0.082920         -0.029387         -0.020745         -0.018673  \n",
       "9          0.082920         -0.029387         -0.020745         -0.018673  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.causal_graph import *\n",
    "from src.scm.feedforward_ncm import FF_NCM\n",
    "from src.scm.distribution import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "from src.data import NCMDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/df_dep.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6e2de",
   "metadata": {},
   "source": [
    "# Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d9b1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'Gender'\n",
    "\n",
    "Z = [\n",
    "    'Age',\n",
    "    'Family History of Mental Illness',\n",
    "    'Sleep Duration'\n",
    "]\n",
    "\n",
    "W = [\n",
    "    'Academic Pressure',\n",
    "    'Work Pressure',\n",
    "    'CGPA',\n",
    "    'Study Satisfaction',\n",
    "    'Dietary Habits',\n",
    "    'Have you ever had suicidal thoughts ?',\n",
    "    'Work/Study Hours',\n",
    "    'Financial Stress',\n",
    "    'degree_level',\n",
    "    'degree_cluster',\n",
    "    'degree_emb_pca_1',\n",
    "    'degree_emb_pca_2',\n",
    "    'degree_emb_pca_3',\n",
    "    'degree_emb_pca_4',\n",
    "    'degree_emb_pca_5'\n",
    "]\n",
    "Y = 'Depression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9571b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_fairness_model = create_expanded_sfm(X, Z, W, Y)\n",
    "ncm = FF_NCM(standard_fairness_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8351d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ncm(model, dataloader, loss_fns, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            # if DataLoader gives you back a list of samples, collate it\n",
    "            if isinstance(batch, list):\n",
    "                batch = default_collate(batch)\n",
    "\n",
    "            # now batch is a dict of batched tensors\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            batch_size = next(iter(batch.values())).shape[0]\n",
    "\n",
    "            # sample exogenous noise\n",
    "            u = model.pu.sample(n=batch_size, device=device)\n",
    "\n",
    "            # accumulate loss over all nodes\n",
    "            total_loss = 0.0\n",
    "            for v in model.v:\n",
    "                pa_keys = model.cg.pa[v]\n",
    "                pa_vals = {k: batch[k] for k in pa_keys}\n",
    "\n",
    "                u_keys = model.cg.v2c2[v]\n",
    "                u_vals = {k: u[k] for k in u_keys}\n",
    "\n",
    "                pred_v = model.f[v](pa=pa_vals, u=u_vals)\n",
    "                loss_v = loss_fns[v](pred_v, batch[v])\n",
    "                total_loss += loss_v\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6765628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (10779, 19) (10779,)\n",
      "Validation data shape: (3593, 19) (3593,)\n",
      "Test data shape: (3593, 19) (3593,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop('Depression', axis=1)\n",
    "y = df['Depression']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d67ada1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [32, 19] at entry 0 and [32, 1] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train for a few epochs for quick testing\u001b[39;00m\n\u001b[0;32m     21\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 22\u001b[0m trained_ncm \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ncm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mncm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compute accuracy on Y\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_accuracy\u001b[39m(model, dataloader, device, target_var):\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mtrain_ncm\u001b[1;34m(model, dataloader, loss_fns, optimizer, device, num_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# if DataLoader gives you back a list of samples, collate it\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# now batch is a dict of batched tensors\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [32, 19] at entry 0 and [32, 1] at entry 1"
     ]
    }
   ],
   "source": [
    "variables = [X] + Z + W + [Y]\n",
    "\n",
    "train_set = NCMDataset(X_train, y_train)\n",
    "test_set = NCMDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
    "\n",
    "loss_fns = {}\n",
    "binary_vars = [X, 'Family History of Mental Illness', 'Have you ever had suicidal thoughts ?', Y]\n",
    "for v in variables:\n",
    "    if v in binary_vars:\n",
    "        loss_fns[v] = nn.BCELoss()\n",
    "    else:\n",
    "        loss_fns[v] = nn.MSELoss()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "optimizer = optim.Adam(ncm.parameters(), lr=1e-3)\n",
    "\n",
    "# Train for a few epochs for quick testing\n",
    "num_epochs = 3\n",
    "trained_ncm = train_ncm(ncm, train_dataloader, loss_fns, optimizer, 'cpu', num_epochs)\n",
    "\n",
    "# Compute accuracy on Y\n",
    "def compute_accuracy(model, dataloader, device, target_var):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            batch_size = next(iter(batch.values())).shape[0]\n",
    "            u = model.pu.sample(n=batch_size, device=device)\n",
    "            preds = model.f[target_var](\n",
    "                pa={k: batch[k] for k in model.cg.pa[target_var]},\n",
    "                u={k: u[k] for k in model.cg.v2c2[target_var]}\n",
    "            )\n",
    "            labels = batch[target_var]\n",
    "            pred_labels = (preds > 0.5).float()\n",
    "            correct += (pred_labels == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "    return correct / total\n",
    "\n",
    "train_acc = compute_accuracy(trained_ncm, train_dataloader, 'cpu', Y)\n",
    "print(f'Final train accuracy for {Y}: {train_acc:.4f}')\n",
    "\n",
    "test_acc = compute_accuracy(trained_ncm, test_dataloader, 'cpu', Y)\n",
    "print(f'Final test accuracy  for {Y}: {test_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
